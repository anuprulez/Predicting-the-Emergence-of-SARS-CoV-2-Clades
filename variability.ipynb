{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import scipy.stats as stats\n",
    "import scipy.io as io\n",
    "import networkx as nx\n",
    "import random\n",
    "import itertools\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import seaborn as sns\n",
    "from scipy.io import loadmat, savemat\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from numpy import arange,array,ones,linalg\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "import powerlaw\n",
    "import os.path\n",
    "from os import path\n",
    "from scipy.optimize import curve_fit\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Calculate entropy\n",
    "def Entropy_MC(s,b,k,beta,gamma):\n",
    "    inv, l, n = k-b, len(s), 4**k\n",
    "    T=np.zeros((n,n))\n",
    "    count = [0]*n\n",
    "    word_list = [''.join(x) for x in itertools.product('acgt', repeat=k)]\n",
    "    wd = dict(zip(word_list, list(range(len(word_list)))))\n",
    "    uu = []\n",
    "    for i in range(k,l-b):\n",
    "        n1, n2 = wd[s[i-k:i]], wd[s[i-k+b:i+b]]\n",
    "        T[n1,n2] += 1\n",
    "        count[n1] += 1\n",
    "        \n",
    "    wo_next = [''.join(x) for x in itertools.product('acgt', repeat=b)]\n",
    "    \n",
    "    for i in range(n):\n",
    "        wo = word_list[i]\n",
    "        for l in wo_next:\n",
    "            j = wd[wo[b:]+l]\n",
    "            T[i,j] = (T[i,j]+beta)/(count[i]+4**b*beta)\n",
    "    sum_count = np.sum(count)+4**k*gamma\n",
    "    \n",
    "    prob = [(count[i]+gamma)/sum_count for i in range(len(count))] \n",
    "    return T,prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def getSeqs(filename):\n",
    "    seq_list = defaultdict(list)\n",
    "    mapseq_list =  defaultdict(list)\n",
    "    mapping = {'A': 'a', 'T': 't', 'C': 'c', 'G': 'g','a': 'a', 't': 't', 'c': 'c', 'g': 'g'}\n",
    "    with open(filename) as f:\n",
    "        j = -1\n",
    "        for i, line in enumerate(f):\n",
    "            if line.startswith('>'):\n",
    "                j += 1\n",
    "            else:\n",
    "                this_line = list(line)\n",
    "                this_line = list(filter(lambda ch: ch in 'acgtACGT', this_line))\n",
    "                seq_list[j].extend(this_line)\n",
    "                mapseq_list[j] = ''.join(list(map(lambda ch: mapping[ch], seq_list[j])))\n",
    "    return mapseq_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats(s,b,k,beta,gamma):\n",
    "    T_list = []\n",
    "    prob_list=[]\n",
    "    for i in range(len(s)):\n",
    "        T,prob = Entropy_MC(s[i],b,k,beta,gamma)\n",
    "        T_list.append(T)\n",
    "        prob_list.append(prob)\n",
    "    return T_list,prob_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_generate(folder):\n",
    "    filenames= glob.glob(folder+'/2020*.fasta')\n",
    "    filenames.sort()\n",
    "    print(filenames)\n",
    "    seq = []\n",
    "    for filename in filenames:\n",
    "        s = getSeqs(filename)\n",
    "        print(len(s))\n",
    "        seq.append(s)\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = seq_generate('USA') # change to seq = seq_generate('Europe') for European Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def high_transitions(seq,b,k,beta,gamma,folder):\n",
    "    n = 4**k\n",
    "    word_list = [''.join(x) for x in itertools.product('acgt', repeat=k)]\n",
    "    wd = dict(zip(word_list, list(range(len(word_list)))))\n",
    "    wo_next = [''.join(x) for x in itertools.product('acgt', repeat=b)]\n",
    "    ctr = 0\n",
    "    sseq = []\n",
    "    m_val = 0\n",
    "    for s in seq:\n",
    "        if len(s)>=10:\n",
    "            sseq.append(s)\n",
    "            if len(s) > m_val:\n",
    "                m_val = len(s)\n",
    "    \n",
    "    d = len(sseq)\n",
    "    \n",
    "    a_mean = np.zeros((d,n))\n",
    "    c_mean = np.zeros((d,n))\n",
    "    g_mean = np.zeros((d,n))\n",
    "    t_mean = np.zeros((d,n))\n",
    "    a_std = np.zeros((d,n))\n",
    "    c_std = np.zeros((d,n))\n",
    "    g_std = np.zeros((d,n))\n",
    "    t_std = np.zeros((d,n))\n",
    "    f_a_mean = np.zeros((d,n))\n",
    "    f_c_mean = np.zeros((d,n))\n",
    "    f_g_mean = np.zeros((d,n))\n",
    "    f_t_mean = np.zeros((d,n))\n",
    "    f_a_std = np.zeros((d,n))\n",
    "    f_c_std = np.zeros((d,n))\n",
    "    f_g_std = np.zeros((d,n))\n",
    "    f_t_std = np.zeros((d,n))\n",
    "    pp_mean = []\n",
    "    pp_std = []\n",
    "    ent_mean = []\n",
    "    ent_std = []\n",
    "    for s in sseq:\n",
    "        print('TIME_FRAME {}'.format(ctr))\n",
    "        T_list,prob_list = stats(s,b,k,beta,gamma)\n",
    "        pp = np.mean(prob_list,axis = 0)\n",
    "        pp_mean.append(pp)\n",
    "        pp = np.std(prob_list,axis = 0)\n",
    "        pp_std.append(pp)\n",
    "        i = 0\n",
    "        AA = [[] for cc in range(n)]\n",
    "        CC = [[] for cc in range(n)]\n",
    "        BB = np.zeros((len(T_list),n))\n",
    "        ENT = np.zeros((len(T_list),1))\n",
    "        for Q in T_list:\n",
    "            ct = 0\n",
    "            for r in Q:\n",
    "                R = r[np.nonzero(r)]\n",
    "                AA[ct]+= [R]\n",
    "                ct+=1\n",
    "            i+=1\n",
    "        \n",
    "        \n",
    "        \n",
    "            \n",
    "\n",
    "        UU_mean = np.zeros((n,4))\n",
    "        UU_std = np.zeros((n,4))\n",
    "        AA = np.array(AA)\n",
    "        print(AA.shape)\n",
    "        for jj in range(n):\n",
    "            UU_mean[jj] = np.mean(AA[jj],axis = 0)\n",
    "            UU_std[jj] = np.std(AA[jj],axis = 0)\n",
    "            \n",
    "        a_mean[ctr] = UU_mean[:,0]\n",
    "        c_mean[ctr] = UU_mean[:,1]\n",
    "        g_mean[ctr] = UU_mean[:,2]\n",
    "        t_mean[ctr] = UU_mean[:,3]\n",
    "        a_std[ctr] = UU_std[:,0]\n",
    "        c_std[ctr] = UU_std[:,1]\n",
    "        g_std[ctr] = UU_std[:,2]\n",
    "        t_std[ctr] = UU_std[:,3]\n",
    "        ctr+=1\n",
    "        #print('------------------------------------------------------------')\n",
    "    a_mean = a_mean.T\n",
    "    c_mean = c_mean.T\n",
    "    g_mean = g_mean.T\n",
    "    t_mean = t_mean.T\n",
    "    a_std = a_std.T\n",
    "    c_std = c_std.T\n",
    "    g_std = g_std.T\n",
    "    t_std = t_std.T\n",
    "    #print(ent_mean,ent_std)\n",
    "    return a_mean,c_mean,g_mean,t_mean,a_std,c_std,g_std,t_std,d,n\n",
    "def file_generation(a_mean,c_mean,g_mean,t_mean,a_std,c_std,g_std,t_std,d,b,k,stdev,folder):\n",
    "    x = [i for i in range(d)]\n",
    "    word_list = [''.join(x) for x in itertools.product('acgt', repeat=k)]\n",
    "    wd = dict(zip(word_list, list(range(len(word_list)))))\n",
    "    wo_next = [''.join(x) for x in itertools.product('acgt', repeat=b)]\n",
    "    n = 4**k\n",
    "    ct_a = ct_c = ct_g = ct_t = 0\n",
    "    tps = []\n",
    "    l_hertz = []\n",
    "    g_hertz = []\n",
    "    for v in range(n):\n",
    "        if np.std(a_mean[v]) > stdev:\n",
    "            \n",
    "            l_hertz.append(a_mean[v])\n",
    "            g_hertz.append(a_std[v])\n",
    "            ct_a+=1\n",
    "            tps.append(word_list[v]+' -> a')\n",
    "\n",
    "        if np.std(c_mean[v]) > stdev:\n",
    "            l_hertz.append(c_mean[v])\n",
    "            g_hertz.append(c_std[v])\n",
    "            ct_c+=1\n",
    "            tps.append(word_list[v]+' -> c')\n",
    "            \n",
    "        if np.std(g_mean[v]) > stdev:\n",
    "            l_hertz.append(g_mean[v])\n",
    "            g_hertz.append(g_std[v])\n",
    "            ct_g+=1\n",
    "            tps.append(word_list[v]+' -> g')\n",
    "            \n",
    "        if np.std(t_mean[v]) > stdev:\n",
    "            l_hertz.append(t_mean[v])\n",
    "            g_hertz.append(t_std[v])\n",
    "            ct_t+=1\n",
    "            tps.append(word_list[v]+' -> t')\n",
    "            \n",
    "            \n",
    "    \n",
    "    l_hertz = np.array(l_hertz)\n",
    "    g_hertz = np.array(g_hertz)\n",
    "    np.savetxt(folder+'/new_time_series_mean_'+str(k)+'_'+str(stdev)+'.csv', l_hertz, delimiter=\",\")\n",
    "    np.savetxt(folder+'/new_time_series_std_'+str(k)+'_'+str(stdev)+'.csv', g_hertz, delimiter=\",\")\n",
    "    return tps,ct_a,ct_c,ct_g,ct_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 0.5\n",
    "gamma = 0.5\n",
    "l = [[1,4],[1,5]]\n",
    "stdevs = [0.001*(1+i) for i in range(30)]\n",
    "\n",
    "folder = 'USA' #Change to 'Europe' for European Samples\n",
    "for val in l:\n",
    "    a_mean,c_mean,g_mean,t_mean,a_std,c_std,g_std,t_std,d,n = high_transitions(seq,val[0],val[1],beta,gamma,folder)\n",
    "    int_num = []\n",
    "    for stdev in stdevs:\n",
    "        aa = open(folder+'/interesting_transitions_{}_k_{}.txt'.format(stdev,val[1]),'w')\n",
    "        tps,ct_a,ct_c,ct_g,ct_t = file_generation(a_mean,c_mean,g_mean,t_mean,a_std,c_std,g_std,t_std,d,val[0],val[1],stdev,folder)\n",
    "        int_num.append(ct_a+ct_c+ct_g+ct_t)\n",
    "        print(int_num[-1])\n",
    "        aa.write('k = '+str(val[1])+'\\n')\n",
    "        aa.write(str(tps)+'\\n')\n",
    "        aa.write(str(ct_a)+' '+str(ct_c)+' '+str(ct_g)+' '+str(ct_t)+'\\n')\n",
    "        aa.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "stdevs = [0.001*(1+i) for i in range(30)]\n",
    "stdevs = np.array(stdevs)\n",
    "n = 4**(k+1)\n",
    "folders = ['USA','Europe']\n",
    "labels = ['USA','Europe']\n",
    "for i,folder in enumerate(folders):\n",
    "    U =[]\n",
    "    for stdev in stdevs:\n",
    "        filesize = os.path.getsize(folder+'/new_time_series_mean_'+str(k)+'_'+str(stdev)+'.csv')\n",
    "        if filesize == 0:\n",
    "            U.append(0)\n",
    "            continue\n",
    "        df = pd.read_csv(folder+'/new_time_series_mean_'+str(k)+'_'+str(stdev)+'.csv')  \n",
    "        rr = df.shape[0]+1\n",
    "        rr = rr/n*100\n",
    "        U.append(rr)\n",
    "        #U = np.array(U)\n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "    plt.loglog(stdevs,U,label = labels[i])\n",
    "    plt.xlabel('Variability')\n",
    "    plt.ylabel('Transitions (%age)')\n",
    "plt.legend(loc = 'best')   \n",
    "plt.tight_layout()\n",
    "plt.savefig('Variability_US_Europe_{}_log_log.png'.format(k))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "        return (x - x.min(0)) / x.ptp(0)\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "k = 5\n",
    "b = 1\n",
    "folders = ['USA','Europe']\n",
    "labels = ['USA','Europe']\n",
    "colors = ['blue','red']\n",
    "xd = {}\n",
    "yd2 = {}\n",
    "for i,folder in enumerate(folders):\n",
    "    data = loadmat(folder+'/hurst_'+str(k)+'_001.mat')\n",
    "    H = data['h_list']\n",
    "    g = sns.distplot(H, hist=True, kde=True, bins=int(100), color = 'green', hist_kws={'edgecolor':'black'},kde_kws={'linewidth': 4})\n",
    "    line = g.get_lines()[0]\n",
    "    xd[folder] = line.get_xdata()\n",
    "    yd = line.get_ydata()\n",
    "    yd2[folder] = normalize(yd)\n",
    "\n",
    "    plt.xlabel('Hurst Exponent')\n",
    "    plt.ylabel('Density')\n",
    "    plt.title('k = {}, b = 1'.format(k))\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig(folder+'/hurst_exponent_density_'+str(k)+'.png')\n",
    "    plt.close()\n",
    "for i,folder in enumerate(folders):\n",
    "    plt.plot(xd[folder],yd2[folder],label = labels[i],color = colors[i]) \n",
    "plt.legend(loc = 'best')\n",
    "plt.xlabel('Hurst Exponent')\n",
    "plt.ylabel('Density')\n",
    "plt.title('k = {}, b = 1 '.format(k))\n",
    "plt.xlim(0,1)\n",
    "plt.tight_layout()\n",
    "plt.savefig('Hurst_US_Europe_{}.png'.format(k))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
