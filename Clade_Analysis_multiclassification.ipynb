{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import scipy.stats as stats\n",
    "import scipy.io as io\n",
    "import networkx as nx\n",
    "import random\n",
    "import itertools\n",
    "import glob\n",
    "from scipy.stats import linregress\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix,roc_curve,roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import seaborn as sns\n",
    "from scipy.io import loadmat, savemat\n",
    "#from fracModel import fracOrdUU\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from numpy import arange,array,ones,linalg\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "import powerlaw\n",
    "import os.path\n",
    "from os import path\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Calculate entropy\n",
    "def Entropy_MC(s,b,k,beta,gamma):\n",
    "    #s = s\n",
    "    inv, l, n = k-b, len(s), 4**k\n",
    "    T=np.zeros((n,n))\n",
    "    count = [0]*n\n",
    "    word_list = [''.join(x) for x in itertools.product('acgt', repeat=k)]\n",
    "    wd = dict(zip(word_list, list(range(len(word_list)))))\n",
    "    uu = []\n",
    "    for i in range(k,l-b):\n",
    "        n1, n2 = wd[s[i-k:i]], wd[s[i-k+b:i+b]]\n",
    "        T[n1,n2] += 1\n",
    "        count[n1] += 1\n",
    "        \n",
    "    wo_next = [''.join(x) for x in itertools.product('acgt', repeat=b)]\n",
    "    for i in range(n):\n",
    "        wo = word_list[i]\n",
    "        for l in wo_next:\n",
    "            j = wd[wo[b:]+l]\n",
    "            T[i,j] = (T[i,j]+beta)/(count[i]+4**b*beta)\n",
    "    sum_count = np.sum(count)+4**k*gamma\n",
    "    \n",
    "    prob = [(count[i]+gamma)/sum_count for i in range(len(count))] \n",
    "    n = len(T)\n",
    "    H = 0\n",
    "    F = []\n",
    "    for i in range(n):\n",
    "        wo = word_list[i]\n",
    "        for l in wo_next:\n",
    "            j = wd[wo[b:]+l]\n",
    "            F.append(T[i,j])\n",
    "            H-=prob[i]*T[i,j]*np.log2(T[i,j])\n",
    "    return F,H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def getSeqs(filename):\n",
    "    seq_list = defaultdict(list)\n",
    "    mapseq_list = defaultdict(list)\n",
    "    mapping = {'A': 'a', 'T': 't', 'C': 'c', 'G': 'g','a': 'a', 't': 't', 'c': 'c', 'g': 'g'}\n",
    "    with open(filename) as f:\n",
    "        j = -1\n",
    "        for i, line in enumerate(f):\n",
    "            if line.startswith('>'):\n",
    "                j += 1\n",
    "            else:\n",
    "                this_line = list(line)\n",
    "                this_line = list(filter(lambda ch: ch in 'acgtACGT', this_line))\n",
    "                seq_list[j].extend(this_line)\n",
    "                mapseq_list[j] = ''.join(list(map(lambda ch: mapping[ch], seq_list[j])))\n",
    "    return mapseq_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats(s,b,k,beta,gamma):\n",
    "    F_list = []\n",
    "    en_list=[]\n",
    "    for i in range(len(s)):\n",
    "        F_1,en = Entropy_MC(s[i],b,k,beta,gamma) #Transition Probability vector\n",
    "        F = F_1\n",
    "        F_list.append(F)\n",
    "        en_list.append(en)\n",
    "    return F_list,en_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = [['20A'],['19A'],['20B'],['19B'],['20C']]\n",
    "V = []\n",
    "for stat in status:\n",
    "    filenames = []\n",
    "    for s in stat:\n",
    "        filenames.append('Clade_Analysis/'+s+'.fasta')\n",
    "    print(filenames)\n",
    "    sequences = []\n",
    "    for filename in filenames:\n",
    "        sequences.append(getSeqs(filename))  \n",
    "    V.append(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Clade_Analysis/V_clades.pkl','wb') as f:  \n",
    "    pickle.dump(V,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_index(b,k,ind):\n",
    "    word_list = [''.join(x) for x in itertools.product('acgt', repeat=k)]\n",
    "    wd_next = [''.join(x) for x in itertools.product('acgt', repeat=b)]\n",
    "    l = 4**b\n",
    "    rem = ind%l\n",
    "    st =' -> '+wd_next[rem]\n",
    "    num = int(ind/l)\n",
    "    st = word_list[num]+st\n",
    "    return st\n",
    "def normalize(x):\n",
    "        return (x - x.min(0)) / x.ptp(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ML(b,k,V,beta,gamma,classes):\n",
    "    word_list = [''.join(x) for x in itertools.product('acgt', repeat=k)]\n",
    "    wd_next = [''.join(x) for x in itertools.product('acgt', repeat=b)]\n",
    "    X = []\n",
    "    y = []\n",
    "    ct = 0\n",
    "    n = len(V)\n",
    "    G = [[] for i in range(n)]\n",
    "    \n",
    "    for seq in V:\n",
    "        for s in seq:\n",
    "            F_list,en_list = stats(s,b,k,beta,gamma)\n",
    "            G[ct]+=F_list\n",
    "        print(len(G[ct]))\n",
    "        ct+=1\n",
    "    \n",
    "    \n",
    "    min_val = float('inf')\n",
    "    for i in range(n):\n",
    "        if min_val > len(G[i]):\n",
    "            min_val = len(G[i])\n",
    "    #Histograms\n",
    "    \n",
    "    for i in range(n):\n",
    "        random.shuffle(G[i])\n",
    "        X+=[G[i][j] for j in range(len(G[i]))]\n",
    "        y+=[i for j in range(len(G[i]))]\n",
    "    #min_val = int(3*(min_val)/4)   \n",
    "    print('Length of X: {}'.format(len(X)))\n",
    "    X_original = [x_i for x_i in X]\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    X_original = np.array(X_original)\n",
    "    X = preprocessing.scale(X)\n",
    "    U_X = list(X[:min_val])\n",
    "    U_y = list(y[:min_val])\n",
    "    T_X = list(X[min_val:len(G[0])])\n",
    "    T_y = list(y[min_val:len(G[0])])\n",
    "    running_sum = len(G[0])\n",
    "    for i in range(1,n):\n",
    "        U_X+=list(X[running_sum:running_sum+min_val])\n",
    "        U_y+=list(y[running_sum:running_sum+min_val])\n",
    "        T_X+=list(X[running_sum+min_val:running_sum+len(G[i])])\n",
    "        T_y+=list(y[running_sum+min_val:running_sum+len(G[i])])\n",
    "        running_sum+=len(G[i])\n",
    "    zipped_U = list(zip(U_X,U_y))\n",
    "    random.shuffle(zipped_U)\n",
    "    U_X = [x_i for x_i,_ in zipped_U]\n",
    "    U_y = [y_i for _,y_i in zipped_U]\n",
    "    zipped_T = list(zip(T_X,T_y))\n",
    "    random.shuffle(zipped_T)\n",
    "    T_X = [x_i for x_i,_ in zipped_T]\n",
    "    T_y = [y_i for _,y_i in zipped_T]\n",
    "    U_X = np.array(U_X)\n",
    "    U_y = np.array(U_y)\n",
    "    T_X = np.array(T_X)\n",
    "    T_y = np.array(T_y)\n",
    "    return U_X,U_y,X_original,T_X,T_y\n",
    "def build_model(X,y,X_original,b,k,rr,cutoff,T,y_T,f):    #Building model for feature selection\n",
    "    kf = KFold(n_splits = 4)\n",
    "    Acc = []\n",
    "    Acc_T = []\n",
    "    sc_prob_T = []\n",
    "    n = len(rr)\n",
    "    val_score = [[] for i in range(n)]\n",
    "    feat_set = set()\n",
    "    feat_set_ind = set()\n",
    "    D = {}\n",
    "    X_orig_mean = np.mean(X_original,axis = 0)\n",
    "    X_orig_std = np.std(X_original,axis = 0)\n",
    "    fig, ax = plt.subplots()\n",
    "    gg = 0\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    tprs = []\n",
    "    aucs = []\n",
    "    prec = []\n",
    "    rec = []\n",
    "    n_dim = 4**(k+b) \n",
    "    acc_list = []\n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "    for train, test in kf.split(X):\n",
    "        X_train = X[train]\n",
    "        y_train = y[train]\n",
    "        X_test = X[test]\n",
    "        y_test = y[test]\n",
    "        model = XGBClassifier(max_depth=1)\n",
    "        model.fit(X_train, y_train)\n",
    "        imp_feat = model.feature_importances_\n",
    "        imp_indices = np.argsort(imp_feat)\n",
    "        for im in range(cutoff,0,1):\n",
    "            transit = conv_index(b,k,imp_indices[im])\n",
    "            D[transit]  = (round(X_orig_mean[imp_indices[im]],2),round(X_orig_std[imp_indices[im]],4))\n",
    "            feat_set.add(transit)\n",
    "            feat_set_ind.add(imp_indices[im])\n",
    "        #plt.bar(range(len(imp_feat)),imp_feat)\n",
    "        #plt.show()\n",
    "        #plt.close()\n",
    "        imp_feat.sort()\n",
    "        #feature selection and rebuilding the model using selected features\n",
    "        thresh = imp_feat[cutoff]\n",
    "        selection = SelectFromModel(model, threshold=thresh, prefit=True)\n",
    "        select_X_train = selection.transform(X_train)\n",
    "        #selection_model = XGBClassifier(max_depth = 1)\n",
    "        selection_model = LogisticRegression()\n",
    "        selection_model.fit(select_X_train, y_train)\n",
    "        select_X_test = selection.transform(X_test)\n",
    "        scores = selection_model.predict(select_X_test)\n",
    "        scores_prob = selection_model.predict_proba(select_X_test)\n",
    "        if len(T) > 0:\n",
    "            select_T = selection.transform(T)\n",
    "            scores_T = selection_model.predict(select_T)\n",
    "            scores_prob_T = selection_model.predict_proba(select_T)\n",
    "            Acc_T.append(accuracy_score(scores_T,y_T))\n",
    "            sc_prob_T+=list(scores_prob_T)\n",
    "        ctr = 0\n",
    "        for yy in y_test:\n",
    "            val_score[yy].append(scores_prob[ctr])\n",
    "            ctr+=1\n",
    "        ctr = 0\n",
    "        val_score_dis = [0 for i in range(n)]\n",
    "        ctx = [0 for i in range(n)]\n",
    "        for yy in y_test:\n",
    "            if scores[ctr] == yy:\n",
    "                val_score_dis[yy]+=1\n",
    "            ctx[yy]+=1\n",
    "            ctr+=1\n",
    "        for yc in range(n):\n",
    "            val_score_dis[yc] = val_score_dis[yc]/ctx[yc]*100\n",
    "        acc_list.append(val_score_dis)\n",
    "        imp_feat_main = selection_model.coef_\n",
    "        \n",
    "        Acc.append(accuracy_score(scores,y_test))\n",
    "        \n",
    "        gg+=1\n",
    "    Acc = np.array(Acc)\n",
    "    val_score = np.array(val_score)\n",
    "    if len(T)> 0:\n",
    "        Acc_T = np.array(Acc_T)\n",
    "    plt.rcParams.update({'font.size': 18})\n",
    "    acc_list_mean = np.mean(acc_list,axis =0)\n",
    "    acc_list_std = np.std(acc_list,axis =0)\n",
    "    #f.write(\"Mean Accuracy: \"+str(acc_list_mean)+'\\n')\n",
    "    #f.write(\"Std Accuracy: \"+str(acc_list_std)+'\\n')\n",
    "    #print(\"Mean Accuracy: {}\".format(acc_list_mean))\n",
    "    #print(\"Std Accuracy: {}\".format(acc_list_std))\n",
    "    for i in range(n):\n",
    "        probs_mean = np.mean(val_score[i],axis = 0)\n",
    "        probs_std = np.std(val_score[i],axis = 0)\n",
    "        #print(probs_mean)\n",
    "        #print('{}'.format(rr[i]))\n",
    "        #f.write(str(i)+':'+str(probs_mean)+' '+str(probs_std))\n",
    "        #f.write('\\n')\n",
    "        plt.bar(rr,probs_mean,yerr=probs_std, align='center', color=['red', 'green','blue','orange','magenta'], ecolor='black', capsize=10)\n",
    "        plt.ylabel('Probability')\n",
    "        plt.title('{} classification probability'.format(rr[i]))\n",
    "        #plt.show()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('Clade_analysis_FD/{}_{}_{}_multi_clades.png'.format(rr[i],b,k),bbox_inches = 'tight')\n",
    "        plt.close()\n",
    "        \n",
    "    #print('Validation Accuracy:'+str(np.mean(Acc))+' +/- '+str(np.std(Acc)))\n",
    "    \n",
    "    \n",
    "            \n",
    "    #print(\"Important Features: {}\".format(feat_set))\n",
    "    f.write(str(D)+'\\n')\n",
    "    f.write(str(feat_set_ind)+'\\n')\n",
    "    ct_1 = 0\n",
    "    ct_2 = 0\n",
    "    ct_3 = 0\n",
    "    ct_4 = 0\n",
    "    ct_5 = 0\n",
    "    g_ind_20A = []\n",
    "    g_ind_19A = []\n",
    "    g_ind_20B = []\n",
    "    g_ind_19B = []\n",
    "    g_ind_20C = []\n",
    "    if len(T) > 0:\n",
    "        #f.write('Results for Independent Test set: '+str(np.mean(Acc_T))+'+/-'+str(np.std(Acc_T))+'\\n')\n",
    "        probs_mean_T = np.mean(sc_prob_T,axis = 0)\n",
    "        probs_std_T = np.std(sc_prob_T,axis = 0)\n",
    "        for j,v in enumerate(scores_T):\n",
    "            if v == 0:\n",
    "                g_ind_20A.append(j)\n",
    "                ct_1+=1\n",
    "            if v == 1:\n",
    "                g_ind_19A.append(j)\n",
    "                ct_2+=1\n",
    "            if v == 2:\n",
    "                g_ind_20B.append(j)\n",
    "                ct_3+=1\n",
    "            if v == 3:\n",
    "                g_ind_19B.append(j)\n",
    "                ct_4+=1\n",
    "            if v == 4:\n",
    "                g_ind_20C.append(j)\n",
    "                ct_5+=1\n",
    "        #f.write(\"Percentage of {}: {}\".format(rr[0],ct_1/len(scores_T)*100)+'\\n')\n",
    "        #f.write(\"Percentage of {}: {}\".format(rr[1],ct_2/len(scores_T)*100)+'\\n')\n",
    "        #f.write(\"Percentage of {}: {}\".format(rr[2],ct_3/len(scores_T)*100)+'\\n')\n",
    "        #f.write(\"Percentage of {}: {}\".format(rr[3],ct_4/len(scores_T)*100)+'\\n')\n",
    "        #f.write(\"Percentage of {}: {}\".format(rr[4],ct_5/len(scores_T)*100)+'\\n')\n",
    "        plt.bar(rr,probs_mean_T,yerr=probs_std_T, align='center', color=['red', 'green','blue','orange','magenta'], ecolor='black', capsize=10)\n",
    "        plt.ylabel('Probability')\n",
    "        plt.title('classification probability')\n",
    "        #plt.show()\n",
    "        plt.tight_layout()\n",
    "        f.write('20A:'+str(g_ind_20A)+'\\n')\n",
    "        f.write('19A:'+str(g_ind_19A)+'\\n')\n",
    "        f.write('20B:'+str(g_ind_20B)+'\\n')\n",
    "        f.write('19B:'+str(g_ind_19B)+'\\n')\n",
    "        f.write('20C:'+str(g_ind_20C)+'\\n')\n",
    "        \n",
    "    return np.mean(Acc),np.std(Acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ML_different_test(b,k,V,beta,gamma,classes):\n",
    "    word_list = [''.join(x) for x in itertools.product('acgt', repeat=k)]\n",
    "    wd_next = [''.join(x) for x in itertools.product('acgt', repeat=b)]\n",
    "    X = []\n",
    "    y = []\n",
    "    ct = 0\n",
    "    n = len(V)\n",
    "    G = [[] for i in range(n)]\n",
    "    \n",
    "    for seq in V:\n",
    "        for s in seq:\n",
    "            F_list,en_list = stats(s,b,k,beta,gamma)\n",
    "            G[ct]+=F_list\n",
    "        print(len(G[ct]))\n",
    "        ct+=1\n",
    "    \n",
    "    \n",
    "    min_val = float('inf')\n",
    "    for i in range(n-1):\n",
    "        if min_val > len(G[i]):\n",
    "            min_val = len(G[i])\n",
    "    \n",
    "    for i in range(n-1):\n",
    "        random.shuffle(G[i])\n",
    "        X+=[G[i][j] for j in range(len(G[i]))]\n",
    "        y+=[i for j in range(len(G[i]))]\n",
    "    for i in range(n-1,n):\n",
    "        X+=[G[i][j] for j in range(len(G[i]))]\n",
    "        y+=[i for j in range(len(G[i]))]\n",
    "    #min_val = int(3*(min_val)/4)   \n",
    "    print('Length of X: {}'.format(len(X)))\n",
    "    X_original = [x_i for x_i in X]\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    X_original = np.array(X_original)\n",
    "    X = preprocessing.scale(X)\n",
    "    U_X = list(X[:min_val])\n",
    "    U_y = list(y[:min_val])\n",
    "    T_X = list(X[len(G[0])+len(G[1])+len(G[2])+len(G[3])+len(G[4]):])\n",
    "    T_y = list(y[len(G[0])+len(G[1])+len(G[2])+len(G[3])+len(G[4]):])\n",
    "    running_sum = len(G[0])\n",
    "    for i in range(1,n-1):\n",
    "        U_X+=list(X[running_sum:running_sum+min_val])\n",
    "        U_y+=list(y[running_sum:running_sum+min_val])\n",
    "        running_sum+=len(G[i])\n",
    "    zipped_U = list(zip(U_X,U_y))\n",
    "    random.shuffle(zipped_U)\n",
    "    U_X = [x_i for x_i,_ in zipped_U]\n",
    "    U_y = [y_i for _,y_i in zipped_U]\n",
    "    zipped_T = list(zip(T_X,T_y))\n",
    "    #random.shuffle(zipped_T)\n",
    "    T_X = [x_i for x_i,_ in zipped_T]\n",
    "    T_y = [y_i for _,y_i in zipped_T]\n",
    "    U_X = np.array(U_X)\n",
    "    U_y = np.array(U_y)\n",
    "    T_X = np.array(T_X)\n",
    "    T_y = np.array(T_y)\n",
    "    return U_X,U_y,X_original,T_X,T_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ML_same(b,k,V,beta,gamma):\n",
    "    word_list = [''.join(x) for x in itertools.product('acgt', repeat=k)]\n",
    "    wd_next = [''.join(x) for x in itertools.product('acgt', repeat=b)]\n",
    "    X = []\n",
    "    y = []\n",
    "    ct = 0\n",
    "    n = 2\n",
    "    G = [[] for i in range(n)]\n",
    "    UU = []\n",
    "    for seq in V:\n",
    "        for s in seq:\n",
    "            F_list,en_list = stats(s,b,k,beta,gamma)\n",
    "            UU+=F_list\n",
    "        print(len(UU))\n",
    "    lx = len(UU)\n",
    "    ux = int(lx/2)\n",
    "    random.shuffle(UU)\n",
    "    G[0]+=[UU[j] for j in range(ux)]\n",
    "    G[1]+=[UU[j] for j in range(ux,lx)] \n",
    "    print(len(G[0]))\n",
    "    print(len(G[1]))\n",
    "    min_val = float('inf')\n",
    "    for i in range(n):\n",
    "        if min_val > len(G[i]):\n",
    "            min_val = len(G[i])\n",
    "            \n",
    "    for i in range(n):\n",
    "        random.shuffle(G[i])\n",
    "        X+=[G[i][j] for j in range(len(G[i]))]\n",
    "        y+=[i for j in range(len(G[i]))]\n",
    "    #min_val = int(3*(min_val)/4)   \n",
    "    print('Length of X: {}'.format(len(X)))\n",
    "    X_original = [x_i for x_i in X]\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    X_original = np.array(X_original)\n",
    "    X = preprocessing.scale(X)\n",
    "    U_X = list(X[:min_val])\n",
    "    U_y = list(y[:min_val])\n",
    "    T_X = list(X[min_val:len(G[0])])\n",
    "    T_y = list(y[min_val:len(G[0])])\n",
    "    running_sum = len(G[0])\n",
    "    for i in range(1,n):\n",
    "        U_X+=list(X[running_sum:running_sum+min_val])\n",
    "        U_y+=list(y[running_sum:running_sum+min_val])\n",
    "        T_X+=list(X[running_sum+min_val:running_sum+len(G[i])])\n",
    "        T_y+=list(y[running_sum+min_val:running_sum+len(G[i])])\n",
    "        running_sum+=len(G[i])\n",
    "    zipped_U = list(zip(U_X,U_y))\n",
    "    random.shuffle(zipped_U)\n",
    "    U_X = [x_i for x_i,_ in zipped_U]\n",
    "    U_y = [y_i for _,y_i in zipped_U]\n",
    "    zipped_T = list(zip(T_X,T_y))\n",
    "    random.shuffle(zipped_T)\n",
    "    T_X = [x_i for x_i,_ in zipped_T]\n",
    "    T_y = [y_i for _,y_i in zipped_T]\n",
    "    U_X = np.array(U_X)\n",
    "    U_y = np.array(U_y)\n",
    "    T_X = np.array(T_X)\n",
    "    T_y = np.array(T_y)\n",
    "    return U_X,U_y,X_original,T_X,T_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l = [[1,4]]\n",
    "beta = 0.5\n",
    "gamma = 0.5\n",
    "clades = ['20A','19A','20B','19B','20C']\n",
    "folder = 'Clade_Analysis/Multiclassifier'\n",
    "cutoff = -10\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "with open('Clade_Analysis/V_clades.pkl','rb') as g:  \n",
    "    V = pickle.load(g)\n",
    "f = open('Clade_Analysis/Results.txt','w')\n",
    "for val in l:\n",
    "    b,k = val[0],val[1]\n",
    "    X,y,X_original,T,y_T = ML(b,k,V,beta,gamma,clades)\n",
    "    mean,std = build_model(X,y,X_original,b,k,clades,cutoff,T,y_T,f)\n",
    "\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
